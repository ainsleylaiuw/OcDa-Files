{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSD for Each Ship Type for Multiple Locations\n",
    "\n",
    "Uses pickle (json) files to get PSD data and aggregates it in SPDF plot by ship type for 3 locations.\n",
    "\n",
    "Check following list for creation of SPDF with probabilities: https://github.com/Ocean-Data-Lab/Website-backend/blob/master/SpecGraph/SPDF.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import ooipy\n",
    "from ooipy.tools import ooiplotlib as ooiplt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functions as fn\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "# IO\n",
    "from io import BytesIO\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating SPDF plot for each ship type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PSD_dict(meta_data_CSV_path, location):\n",
    "    \"\"\"\n",
    "    Generate a dictionary that holds PSD data\n",
    "    Ex. psd_dict[ship_type][freq_values] # not actual key names\n",
    "    This data gets passed into the spdf generation and plotting functions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    meta_data_CSV_path : str\n",
    "        A file path that points to the .csv that contains the metadata. \n",
    "        Mainly used to group based on ship type (ud_group). Also matches instance_id\n",
    "        to corresponding ship type.\n",
    "\n",
    "    location : str\n",
    "        String containing location of the hydrophone (i.e. Axial_Base).\n",
    "        Used for file pathing\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict: a nested dictionary for ship type and their respective PSD data\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(meta_data_CSV_path, sep=',')\n",
    "\n",
    "    # EC is the only one with missing ship type and only 4 of them, just ignore those\n",
    "    # .dropna() followed by .groupby() cleans and groups\n",
    "    grouped_df = df.dropna(subset=['ud_group']).groupby('ud_group')\n",
    "\n",
    "    # https://stackoverflow.com/questions/27405483/how-to-loop-over-grouped-pandas-dataframe\n",
    "    PSDs = {}\n",
    "    for group_name, df_group in grouped_df:\n",
    "        \n",
    "        PSD_obj_list = []\n",
    "        PSD_freq = []\n",
    "        PSD_val = []\n",
    "        dictPSD = {'objects': PSD_obj_list, 'frequencies': PSD_freq, 'values': PSD_val}\n",
    "\n",
    "        # for-loop to compile list of PSD data objects pulled from column\n",
    "        for row_index, row in df_group.iterrows():\n",
    "            inst_id = df['instance_id'].iloc[row_index]\n",
    "            # get pickle files (DL locally? Call some API?)\n",
    "            # local storage method\n",
    "            data_path = 'data/' + location + '/'\n",
    "            pklfilepath = data_path + 'PSD_pickles/' + inst_id + '.json'\n",
    "            # try-except deals with missing pickles\n",
    "            try:\n",
    "                with open(pklfilepath, 'rb') as f:\n",
    "                    dict1 = json.load(f)\n",
    "\n",
    "                # create PSD object and fill out PSD object fields\n",
    "                psd = ooipy.Psd(dict1['f'], dict1['psd'])\n",
    "                dictPSD['objects'].append(psd)\n",
    "                dictPSD['frequencies'].append(psd.freq)\n",
    "                dictPSD['values'].append(psd.values)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "        PSDs.update({group_name: dictPSD})\n",
    "    return PSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function pulled from https://github.com/Ocean-Data-Lab/Website-backend     \n",
    "def get_spdf(spec, fs_hz=200, fmax=None, spl_bins=np.linspace(0, 120, 481),\n",
    "             percentiles=[1, 5, 10, 50, 90, 95, 99]):\n",
    "    if fmax is None:\n",
    "        fmax = 100 #spec.frequency[-1]\n",
    "\n",
    "    n_freq_bin = int(len(spec['frequencies'][0]) * fmax/(fs_hz/2)) + 1\n",
    "\n",
    "    spdf_dct = {'freq': np.array(np.linspace(0, fmax, n_freq_bin)),\n",
    "                'spl': spl_bins[:-1],\n",
    "                'pdf': np.empty((n_freq_bin, 480))\n",
    "                #'number_psd': len(spec.time) this isn't used\n",
    "                }\n",
    "\n",
    "    for p in percentiles:\n",
    "        spdf_dct[str(p)] = np.empty(n_freq_bin)\n",
    "\n",
    "    for idx, freq_bin in enumerate(np.asarray(spec['values']).T[:n_freq_bin - 1]):\n",
    "        hist, _ = np.histogram(freq_bin, bins=spl_bins, density=True)\n",
    "        spdf_dct['pdf'][idx] = hist\n",
    "        spdf_dct['50'][idx] = np.median(freq_bin)\n",
    "        for p in percentiles:\n",
    "            spdf_dct[str(p)][idx] = np.nanquantile(freq_bin, p/100)\n",
    "\n",
    "    return spdf_dct\n",
    "\n",
    "def plot_spdf(spdf, vmin=0.003, vmax=0.2, vdelta=0.0025, save=False, filename=None, log=True, title='Spectral PDF', shipType=None, location=None):\n",
    "    cbarticks = np.arange(vmin, vmax+vdelta, vdelta)\n",
    "    fig, ax = plt.subplots(figsize=(9, 5))\n",
    "    im = ax.contourf(spdf['freq'], spdf['spl'], np.transpose(spdf['pdf']),\n",
    "                     cbarticks, norm=colors.Normalize(vmin=vmin, vmax=vmax),\n",
    "                     cmap='jet', extend='max', alpha=0.50, linewidth=0)\n",
    "\n",
    "    # plot some percentiles:\n",
    "    plt.plot(spdf['freq'], spdf['1'], color='black')\n",
    "    plt.plot(spdf['freq'], spdf['5'], color='black')\n",
    "    plt.plot(spdf['freq'], spdf['10'], color='black')\n",
    "    plt.plot(spdf['freq'], spdf['50'], color='black')\n",
    "    plt.plot(spdf['freq'], spdf['90'], color='black')\n",
    "    plt.plot(spdf['freq'], spdf['95'], color='black')\n",
    "    plt.plot(spdf['freq'], spdf['99'], color='black')\n",
    "\n",
    "    plt.ylabel(r'spectral level (dB rel $1 \\mathrm{\\frac{Î¼ Pa^2}{Hz}}$)')\n",
    "    plt.xlabel('frequency (Hz)')\n",
    "    plt.ylim([36, 100])\n",
    "    plt.xlim([0, 90])\n",
    "    if log:\n",
    "        plt.xscale('log')\n",
    "\n",
    "    plt.colorbar(im, ax=ax, ticks=[vmin, vmin + (vmax-vmin)/4, vmin + (vmax-vmin)/2,\n",
    "                 vmin + 3*(vmax-vmin)/4,  vmax],  pad=0.03, label='probability', format='%.3f')\n",
    "    plt.tick_params(axis='y')\n",
    "    plt.grid(True)\n",
    "    plt.title(title)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    line = Line2D(\n",
    "        [0], [0], label='percentiles: 1, 5, 10, 50, 90, 95, 99', color='k')\n",
    "    handles.extend([line])\n",
    "    plt.legend(handles=handles, loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.xlim((200/512, 100))\n",
    "    filepath = 'data/'+location+'/'\n",
    "    plt.savefig(filepath+shipType+'.jpg', format='jpg')\n",
    "    plt.close() # suppress plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate plots for 3 locations\n",
    "Oregon Slope and Southern Hyrdate hydrophones do not have data in the sharepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargo\n",
      "Fishing type\n",
      "Passenger\n",
      "Recreational\n",
      "Research\n",
      "Tanker\n"
     ]
    }
   ],
   "source": [
    "AB_PSDs = get_PSD_dict('data/Axial_Base/AB_isolated_ais_10m_5_20.csv', location='Axial_Base')\n",
    "for key in AB_PSDs:\n",
    "    print((key))\n",
    "    spdf = get_spdf(AB_PSDs[key])\n",
    "    plot_spdf(spdf, log=False, title=key + ' Spectral PDF', shipType=key, location='Axial_Base')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargo\n",
      "Fishing type\n",
      "Offshore\n",
      "Other purpose\n",
      "Research\n",
      "Tanker\n"
     ]
    }
   ],
   "source": [
    "CC_PSDs = get_PSD_dict('data/Central_Caldera/CC_isolated_ais_10m_5_20.csv', location='Central_Caldera')\n",
    "for key in CC_PSDs:\n",
    "    print(key)\n",
    "    spdf = get_spdf(CC_PSDs[key])\n",
    "    plot_spdf(spdf, log=False, title=key + ' Spectral PDF', shipType=key, location='Central_Caldera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargo\n",
      "Fishing type\n",
      "Offshore\n",
      "Other purpose\n",
      "Research\n",
      "Tanker\n"
     ]
    }
   ],
   "source": [
    "EC_PSDs = get_PSD_dict('data/Eastern_Caldera/EC_isolated_ais_5_20.csv', location='Eastern_Caldera')\n",
    "for key in EC_PSDs:\n",
    "    print(key)\n",
    "    spdf = get_spdf(EC_PSDs[key])\n",
    "    plot_spdf(spdf, log=False, title=key + ' Spectral PDF', shipType=key, location='Eastern_Caldera')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a881572e0f47ad42fbe19c9bef42a69b454c13522f4345672cdd837ecfaff96a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
